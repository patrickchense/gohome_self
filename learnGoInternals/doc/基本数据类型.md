i := 1234
j := int32(1)

i 是int， 32位， j是int32， i和j类型不同， i = j 编译错误， i = int(j)

##pointer
type Point struct { x, y int}
p := Point{10,20}
pp := &p
ppp := *pp
三个变量的含义

##字符串
go 的字符串2个字的数据结构， 1个指向[]byte, 1个长度
s := "hello"    // &ptr(h), 5  ->  'h','e','l','l','o'
t := s[2:3]  // &ptr(l), 1
slice 字符串得到新的字符串， 字符串的切分可以不涉及内存分配或复制，仅仅类似传递下标

##slice
结构， &ptr， 对应数组的地址， l 长度， cap 容量
长度是下标操作的上界， 容量是分割操作的上界  x[i] < l , x[i:j] j < cap
slice操作足够廉价, 分割不需要分配内存
slice append会扩容，规则：
如果新的大小是当前大小2倍以上，则大小增长为新大小
否则循环以下操作：如果当前大小小于1024，按每次2倍增长，否则每次按当前大小1/4增长。直到增长的大小超过或等于新大小。


##make和new的区别
new(T) 返回一个*T, 返回的指针可以被隐式地消除引用
make(T, args) 返回T,
new 返回一个指向已清零内存的指针，make返回一个复杂结构


##slice和unsafe.Pointer转换
make 得到new , s:=make([]byte, 200)   ptr:=unsafe.Pointer(&s[0])
new 到make， 难多了,   var ptr unsafe.Pointer   s := ((*[1<<10]byte)(ptr))[:200], 1<<10 cap, 200 len
或者:
var ptr unsafe.Pointer
var s1 = struct {
    addr uintptr
    len int
    cap int
}{ptr, length, length}
s := *(*[]byte)(unsafe.Pointer(&s1))

再或者reflect.SliceHeader来构造， 推荐！！！！！
var o []byte
sliceHeader := (*reflect.SliceHeader)(unsafe.Pointer(&o))
sliceHeader.Cap = length
sliceHeader.Len = length
sliceHeader.Data = uintptr(ptr)

##map结构
###底层
struct Hmap
{
	uint8   B;	// 可以容纳2^B个项
	uint16  bucketsize;   // 每个桶的大小

	byte    *buckets;     // 2^B个Buckets的数组
	byte    *oldbuckets;  // 前一个buckets，只有当正在扩容时才不为空
};

这个hash结构使用的是一个可扩展哈希的算法，由hash值mod当前hash表大小决定某一个值属于哪个桶，而hash表大小是2的指数，即上面结构体中的2^B。
每次扩容，会增大到上次大小的两倍。结构体中有一个buckets和一个oldbuckets是用来实现增量扩容的。正常情况下直接使用buckets，而oldbuckets为空。
如果当前哈希表正在扩容中，则oldbuckets不为空，并且buckets大小是oldbuckets大小的两倍

###bucket结构
struct Bucket
{
	uint8  tophash[BUCKETSIZE]; // hash值的高8位....低位从bucket的array定位到bucket
	Bucket *overflow;           // 溢出桶链表，如果有
	byte   data[1];             // BUCKETSIZE keys followed by BUCKETSIZE values
};
其中BUCKETSIZE是用宏定义的8，每个bucket中存放最多8个key/value对, 如果多于8个，那么会申请一个新的bucket，并将它与之前的bucket链起来。
按key的类型采用相应的hash算法得到key的hash值。将hash值的低位当作Hmap结构体中buckets数组的index，找到key所在的bucket。将hash的高8位存储在了bucket的tophash中。
注意，这里高8位不是用来当作key/value在bucket内部的offset的，而是作为一个主键，在查找时对tophash数组的每一项进行顺序匹配的。
先比较hash值高位与bucket的tophash[i]是否相等，如果相等则再比较bucket的第i个的key与所给的key是否相等。如果相等，则返回其对应的value，反之，在overflow buckets中按照上述方法继续寻找。

###扩容
如果扩容前的哈希表大小为2^B，扩容之后的大小为2^(B+1)，每次扩容都变为原来大小的两倍，哈希表大小始终为2的指数倍，则有(hash mod 2^B)等价于(hash & (2^B-1))。这样可以简化运算，避免了取余操作。
假设扩容之前容量为X，扩容之后容量为Y，对于某个哈希值hash，一般情况下(hash mod X)不等于(hash mod Y)，所以扩容之后要重新计算每一项在哈希表中的新位置。
当hash表扩容之后，需要将那些旧的pair重新哈希到新的table上(源代码中称之为evacuate)， 这个工作并没有在扩容之后一次性完成，而是逐步的完成（在insert和remove时每次搬移1-2个pair），
Go语言使用的是增量扩容

为什么会增量扩容呢？主要是缩短map容器的响应时间。假如我们直接将map用作某个响应实时性要求非常高的web应用存储，如果不采用增量扩容，当map里面存储的元素很多之后，扩容时系统就会卡往，
导致较长一段时间内无法响应请求。不过增量扩容本质上还是将总的扩容时间分摊到了每一次哈希操作上面

扩容会建立一个大小是原来2倍的新的表，将旧的bucket搬到新的表中之后，并不会将旧的bucket从oldbucket中删除，而是加上一个已删除的标记
正是由于这个工作是逐渐完成的，这样就会导致一部分数据在old table中，一部分在new table中， 所以对于hash table的insert, remove, lookup操作的处理逻辑产生影响。
只有当所有的bucket都从旧表移到新表之后，才会将oldbucket释放掉

###查找过程
1. 根据key计算出hash值。
2. 如果存在old table, 首先在old table中查找，如果找到的bucket已经evacuated，转到步骤3。 反之，返回其对应的value。
3. 在new table中查找对应的value

###插入过程
1.根据key算出hash值，进而得出对应的bucket。
2.如果bucket在old table中，将其重新散列到new table中。
3.在bucket中，查找空闲的位置，如果已经存在需要插入的key，更新其对应的value。
4.根据table中元素的个数，判断是否grow table。
5.如果对应的bucket已经full，重新申请新的bucket作为overbucket。
6.将key/value pair插入到bucket中。
在扩容过程中，oldbucket是被冻结的，查找时会在oldbucket中查找，但不会在oldbucket中插入数据。如果在oldbucket是找到了相应的key，做法是将它迁移到新bucket后加入evalucated标记。
并且还会额外的迁移另一个pair。
然后就是只要在某个bucket中找到第一个空位，就会将key/value插入到这个位置。也就是位置位于bucket前面的会覆盖后面的(类似于存储系统设计中做删除时的常用的技巧之一，直接用新数据追加方式写，
新版本数据覆盖老版本数据)。找到了相同的key或者找到第一个空位就可以结束遍历了。不过这也意味着做删除时必须完全的遍历bucket所有溢出链，将所有的相同key数据都删除。
所以目前map的设计是为插入而优化的，删除效率会比插入低一些。

##nil语义
按照Go语言规范，任何类型在未初始化时都对应一个零值：布尔类型是false，整型是0，字符串是""，而指针，函数，interface，slice，channel和map的零值都是nil。  

###interface
一个interface在没有进行初始化时，对应的值是nil。也就是说var v interface{}
此时v就是一个nil。在底层存储上，它是一个空指针。与之不同的情况是，interface值为空

###string和slice
string空值是"", 不能跟nil比较，空的string，大小也是2个机器字长
slice类似，空值是3个机器字长，指针域是nil

###channel和map
channel在stack中只有一个指针，指向heap，channel未初始化是nil，不能使用
* 读写一个nil的channel会阻塞
* 读一个关闭的channel会立刻返回一个channel元素类型的零值
* 写一个关闭的channel会panic
map也是指针，nil，指向heap




